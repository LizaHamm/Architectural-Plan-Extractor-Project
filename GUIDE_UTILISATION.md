# üìñ Guide d'Utilisation - Extraction de Plans Num√©riques

## üöÄ Guide Complet pour Ex√©cuter le Projet

Ce guide vous explique √©tape par √©tape comment utiliser le notebook `extraction_plans_architecte.ipynb` pour extraire des plans num√©riques depuis des PDFs d'architecte.

---

## üìã Table des Mati√®res

1. [Pr√©requis et Installation](#pr√©requis-et-installation)
2. [Configuration Initiale](#configuration-initiale)
3. [Ex√©cution du Notebook](#ex√©cution-du-notebook)
4. [Workflow Complet](#workflow-complet)
5. [D√©tection et Extraction](#d√©tection-et-extraction)
6. [Visualisation des R√©sultats](#visualisation-des-r√©sultats)
7. [D√©pannage](#d√©pannage)

---

## 1. Pr√©requis et Installation

### 1.1 Environnement Python

```bash
# Python 3.8 ou sup√©rieur requis
python --version

# Cr√©er un environnement virtuel (recommand√©)
python -m venv venv

# Activer l'environnement
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

### 1.2 Installation des D√©pendances

```bash
# Installer toutes les d√©pendances
pip install -r requirements.txt

# OU installer manuellement:
pip install opencv-python pillow scikit-image ultralytics torch torchvision
pip install PyMuPDF pdf2image pdfplumber
pip install openai anthropic transformers langchain
pip install diffusers controlnet-aux
pip install snowflake-connector-python snowflake-sqlalchemy
pip install matplotlib plotly seaborn
pip install ezdxf ifcopenshell
pip install pandas numpy scipy ipywidgets
```

### 1.3 Installation de Jupyter

```bash
pip install jupyter notebook
# OU
pip install jupyterlab
```

### 1.4 T√©l√©chargement des Mod√®les YOLO

Les mod√®les YOLO seront t√©l√©charg√©s automatiquement au premier usage, mais vous pouvez les pr√©-t√©l√©charger.

**M√©thode 1: Dans le Notebook (RECOMMAND√â)**
- Ex√©cuter la cellule **1.4** du notebook qui t√©l√©charge automatiquement les mod√®les

**M√©thode 2: Script Python s√©par√©**
```bash
# Ex√©cuter le script fourni
python download_models.py
```

**M√©thode 3: PowerShell/CMD (Windows)**
```powershell
# Activer l'environnement virtuel d'abord
venv\Scripts\activate

# Puis ex√©cuter Python directement
python -c "from ultralytics import YOLO; YOLO('yolo11n.pt'); YOLO('yolo11n-seg.pt'); YOLO('yolo11n-pose.pt')"
```

**M√©thode 4: Terminal Linux/Mac**
```bash
# Activer l'environnement virtuel
source venv/bin/activate

# Ex√©cuter
python -c "from ultralytics import YOLO; YOLO('yolo11n.pt'); YOLO('yolo11n-seg.pt'); YOLO('yolo11n-pose.pt')"
```

**Note**: Si vous ne t√©l√©chargez pas les mod√®les maintenant, ils le seront automatiquement lors de leur premi√®re utilisation dans la Section 5 (Labellisation).

---

## 2. Configuration Initiale

### 2.1 Variables d'Environnement (Optionnel)

Cr√©ez un fichier `.env` ou configurez les variables d'environnement:

```bash
# Snowflake (optionnel)
export SNOWFLAKE_ACCOUNT="votre_compte"
export SNOWFLAKE_USER="votre_utilisateur"
export SNOWFLAKE_PASSWORD="votre_mot_de_passe"
export SNOWFLAKE_WAREHOUSE="COMPUTE_WH"
export SNOWFLAKE_DATABASE="ARCHITECTURE_DB"
export SNOWFLAKE_SCHEMA="PLANS_SCHEMA"

# OpenAI (pour g√©n√©ration de donn√©es)
export OPENAI_API_KEY="votre_cl√©_api"
```

### 2.2 Structure des R√©pertoires

Le notebook cr√©era automatiquement cette structure:

```
ArchiProject/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ pdfs/              # Placez vos PDFs ici
‚îÇ   ‚îú‚îÄ‚îÄ images/            # Images extraites
‚îÇ   ‚îú‚îÄ‚îÄ annotations/       # Annotations YOLO
‚îÇ   ‚îú‚îÄ‚îÄ synthetic_images/   # Images g√©n√©r√©es
‚îÇ   ‚îî‚îÄ‚îÄ scenarios_llm.json # Sc√©narios g√©n√©r√©s
‚îú‚îÄ‚îÄ models/                # Mod√®les entra√Æn√©s
‚îú‚îÄ‚îÄ output/                # R√©sultats finaux
‚îî‚îÄ‚îÄ extraction_plans_architecte.ipynb
```

### 2.3 Pr√©parer vos Donn√©es

1. **Placer vos PDFs** dans `data/pdfs/`
   ```bash
   # Exemple
   cp vos_plans.pdf data/pdfs/
   ```

2. **V√©rifier la structure**
   ```python
   from pathlib import Path
   pdf_dir = Path("data/pdfs")
   pdfs = list(pdf_dir.glob("*.pdf"))
   print(f"Nombre de PDFs trouv√©s: {len(pdfs)}")
   ```

---

## 3. Ex√©cution du Notebook

### 3.1 Lancer Jupyter

```bash
# Depuis le r√©pertoire du projet
jupyter notebook

# OU avec JupyterLab
jupyter lab
```

### 3.2 Ouvrir le Notebook

1. Ouvrir `extraction_plans_architecte.ipynb`
2. Ex√©cuter les cellules **dans l'ordre** (Kernel ‚Üí Restart & Run All)

### 3.3 Ex√©cution S√©quentielle

**IMPORTANT**: Ex√©cutez les sections dans l'ordre:

1. ‚úÖ **Section 1**: Setup et Imports (obligatoire)
2. ‚úÖ **Section 2**: Snowflake Configuration (optionnel)
3. ‚úÖ **Section 3**: Extraction PDF (obligatoire)
4. ‚ö†Ô∏è **Section 4**: G√©n√©ration Donn√©es LLM (optionnel, long)
5. ‚úÖ **Section 5**: Labellisation (obligatoire)
6. ‚ö†Ô∏è **Section 6**: Entra√Ænement YOLO (optionnel, tr√®s long)
7. ‚úÖ **Section 7**: Inf√©rence (obligatoire)
8. ‚úÖ **Section 8**: Visualisation (obligatoire)
9. ‚úÖ **Section 9**: Tests (recommand√©)

---

## 4. Workflow Complet

### 4.1 Workflow Minimal (Sans Entra√Ænement)

```python
# 1. Setup (Section 1)
# ‚úÖ Ex√©cuter toutes les cellules de la Section 1

# 2. Configuration Snowflake (Section 2)
# ‚ö†Ô∏è Optionnel - peut √™tre ignor√© si pas de Snowflake

# 3. Extraction PDF (Section 3)
pdf_path = "data/pdfs/mon_plan.pdf"
result = process_pdf(pdf_path)
print(f"‚úÖ {len(result['images'])} pages extraites")

# 4. Preprocessing (Section 3)
image_path = result['saved_paths'][0]
processed_img = preprocess_image(image_path)

# 5. Labellisation avec YOLO pr√©-entra√Æn√© (Section 5)
annotations = labeler.label_image(image_path)
print(f"‚úÖ {len(annotations['detections'])} d√©tections trouv√©es")

# 6. Visualisation (Section 8)
fig = labeler.visualize_annotations(image_path, annotations)
plt.show()

# 7. Extraction vectorielle (Section 7)
# Voir section d√©taill√©e ci-dessous
```

### 4.2 Workflow Complet (Avec Entra√Ænement)

```python
# 1-3. Setup, Snowflake, Extraction (comme ci-dessus)

# 4. G√©n√©ration de donn√©es synth√©tiques (Section 4)
scenarios = llm_generator.generate_scenarios_openai()
generated_images = image_generator.generate_images_from_scenarios(
    scenarios[:10],  # Limiter pour test
    config.DATA_DIR / "synthetic_images"
)

# 5. Augmentation de donn√©es (Section 4)
augmented = augmenter.augment_dataset(
    result['saved_paths'],
    config.DATA_DIR / "augmented"
)

# 6. Pr√©paration dataset (Section 6)
yolo_dir = Path("data/yolo_dataset")
dataset_prep.create_yolo_structure(yolo_dir)
splits = dataset_prep.split_dataset(
    result['saved_paths'] + augmented,
    train_ratio=0.7, val_ratio=0.2, test_ratio=0.1
)
dataset_prep.copy_to_yolo_structure(splits, yolo_dir, config.ANNOTATIONS_DIR)
config_path = dataset_prep.create_yolo_config(yolo_dir, len(config.CLASSES))

# 7. Entra√Ænement YOLO (Section 6)
# Voir section d√©taill√©e ci-dessous

# 8. Inf√©rence avec mod√®le entra√Æn√© (Section 7)
# Voir section d√©taill√©e ci-dessous
```

---

## 5. D√©tection et Extraction

### 5.1 D√©tection Simple (YOLO Pr√©-entra√Æn√©)

```python
# Charger une image
image_path = "data/images/mon_plan_page_001.png"

# D√©tection
annotations = labeler.label_image(image_path)

# Afficher les r√©sultats
print(f"Nombre de d√©tections: {len(annotations['detections'])}")
for det in annotations['detections']:
    print(f"  - {det['class_name']}: confiance {det['confidence']:.2f}")

# Visualiser
fig = labeler.visualize_annotations(image_path, annotations)
plt.show()
```

### 5.2 D√©tection Compl√®te (D√©tection + Segmentation + Keypoints)

```python
# D√©tection
detections = labeler.predict_detection(image_path)

# Segmentation
segmentations = labeler.predict_segmentation(image_path)

# Keypoints
keypoints = labeler.predict_keypoints(image_path)

# Combiner
full_annotations = {
    'detections': detections,
    'segmentations': segmentations,
    'keypoints': keypoints
}

# Sauvegarder
save_annotations_snowflake("plan_001", full_annotations)
```

### 5.3 Traitement d'un PDF Complet

```python
def process_complete_pdf(pdf_path: str):
    """Traite un PDF complet de bout en bout"""
    
    # 1. Extraction
    print("üìÑ Extraction des pages...")
    result = process_pdf(pdf_path)
    
    if not result:
        print("‚ùå Erreur lors de l'extraction")
        return None
    
    # 2. Preprocessing
    print("üîß Preprocessing...")
    processed_images = []
    for img_path in result['saved_paths']:
        processed = preprocess_image(img_path)
        processed_path = config.IMAGES_DIR / f"processed_{Path(img_path).name}"
        processed.save(processed_path)
        processed_images.append(str(processed_path))
    
    # 3. D√©tection sur chaque page
    print("üîç D√©tection des √©l√©ments...")
    all_annotations = []
    for img_path in processed_images:
        annotations = labeler.label_image(img_path)
        all_annotations.append(annotations)
        print(f"  ‚úì {len(annotations['detections'])} d√©tections sur {Path(img_path).name}")
    
    # 4. R√©sum√©
    total_detections = sum(len(ann['detections']) for ann in all_annotations)
    print(f"\n‚úÖ Traitement termin√©: {total_detections} d√©tections au total")
    
    return {
        'plan_data': result['plan_data'],
        'annotations': all_annotations,
        'images': processed_images
    }

# Utilisation
result = process_complete_pdf("data/pdfs/mon_plan.pdf")
```

### 5.4 Extraction Vectorielle (DXF/IFC)

```python
# Voir Section 7 du notebook pour le code complet
# Exemple simplifi√©:

from export_vectoriel import VectorExporter

exporter = VectorExporter(config)

# Exporter en DXF
dxf_path = exporter.export_to_dxf(
    image_path="data/images/plan.png",
    annotations=annotations,
    output_path="output/plan.dxf"
)

# Exporter en IFC (BIM)
ifc_path = exporter.export_to_ifc(
    image_path="data/images/plan.png",
    annotations=annotations,
    output_path="output/plan.ifc"
)
```

---

## 6. Visualisation des R√©sultats

### 6.1 Visualisation Simple

```python
# Visualiser les annotations
image_path = "data/images/mon_plan_page_001.png"
annotations = labeler.label_image(image_path)

fig = labeler.visualize_annotations(image_path, annotations)
plt.show()
```

### 6.2 Dashboard Interactif (Plotly)

```python
# Voir Section 8 du notebook
# Le notebook contient un dashboard interactif complet

from dashboard import create_dashboard

# Cr√©er le dashboard
dashboard = create_dashboard(annotations, image_path)
dashboard.show()
```

### 6.3 Comparaison Avant/Apr√®s

```python
# Charger image originale
original = Image.open(image_path)

# Charger image avec annotations
annotated = labeler.visualize_annotations(image_path, annotations)

# Comparaison c√¥te √† c√¥te
fig, axes = plt.subplots(1, 2, figsize=(20, 10))
axes[0].imshow(original)
axes[0].set_title("Original")
axes[0].axis('off')

axes[1].imshow(annotated)
axes[1].set_title("Avec D√©tections")
axes[1].axis('off')

plt.tight_layout()
plt.show()
```

### 6.4 Statistiques et M√©triques

```python
# Analyser les d√©tections
import pandas as pd

# Cr√©er un DataFrame
detections_data = []
for ann in all_annotations:
    for det in ann['detections']:
        detections_data.append({
            'classe': det['class_name'],
            'confidence': det['confidence'],
            'page': ann.get('page', 0)
        })

df = pd.DataFrame(detections_data)

# Statistiques
print("üìä Statistiques des d√©tections:")
print(df.groupby('classe').agg({
    'confidence': ['mean', 'count']
}))

# Graphique
import seaborn as sns
sns.countplot(data=df, x='classe')
plt.xticks(rotation=45)
plt.title("Distribution des classes d√©tect√©es")
plt.show()
```

---

## 7. Entra√Ænement YOLO (Optionnel)

### 7.1 Pr√©paration du Dataset

```python
# 1. Collecter toutes les images
all_images = list(config.IMAGES_DIR.glob("*.png"))
all_images += list((config.DATA_DIR / "synthetic_images").glob("*.png"))
all_images += list((config.DATA_DIR / "augmented").glob("*.png"))

# 2. Cr√©er structure YOLO
yolo_dir = Path("data/yolo_dataset")
dataset_prep.create_yolo_structure(yolo_dir)

# 3. Split train/val/test
splits = dataset_prep.split_dataset(
    [str(p) for p in all_images],
    train_ratio=0.7, val_ratio=0.2, test_ratio=0.1
)

# 4. Copier dans structure YOLO
dataset_prep.copy_to_yolo_structure(
    splits, 
    yolo_dir, 
    config.ANNOTATIONS_DIR
)

# 5. Cr√©er config
config_path = dataset_prep.create_yolo_config(
    yolo_dir, 
    len(config.CLASSES)
)
```

### 7.2 Entra√Ænement

```python
from ultralytics import YOLO

# Charger mod√®le pr√©-entra√Æn√©
model = YOLO("yolo11n.pt")

# Entra√Æner
results = model.train(
    data=str(config_path),  # Chemin vers data.yaml
    epochs=100,
    imgsz=640,
    batch=16,
    name="plans_architecte",
    project="models"
)

# Le mod√®le sera sauvegard√© dans models/plans_architecte/
```

### 7.3 √âvaluation

```python
# √âvaluer le mod√®le
metrics = model.val()

print(f"mAP50: {metrics.box.map50}")
print(f"mAP50-95: {metrics.box.map}")
print(f"Precision: {metrics.box.mp}")
print(f"Recall: {metrics.box.mr}")
```

### 7.4 Utiliser le Mod√®le Entra√Æn√©

```python
# Charger le mod√®le entra√Æn√©
trained_model = YOLO("models/plans_architecte/weights/best.pt")

# Utiliser pour d√©tection
results = trained_model.predict(
    "data/images/nouveau_plan.png",
    conf=0.25
)

# Visualiser
results[0].show()
```

---

## 8. Interface Streamlit (Optionnel)

### 8.1 Cr√©er l'Interface

Cr√©ez un fichier `app_streamlit.py`:

```python
import streamlit as st
from PIL import Image
import sys
sys.path.append('.')

# Importer les fonctions du notebook
from extraction_plans_architecte import (
    process_pdf, labeler, config
)

st.title("üèóÔ∏è Extraction de Plans Num√©riques")

# Upload PDF
uploaded_file = st.file_uploader("T√©l√©charger un PDF", type="pdf")

if uploaded_file:
    # Sauvegarder temporairement
    with open("temp.pdf", "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    # Traiter
    if st.button("Extraire"):
        with st.spinner("Traitement en cours..."):
            result = process_pdf("temp.pdf")
            
            if result:
                st.success(f"‚úÖ {len(result['images'])} pages extraites")
                
                # Afficher premi√®re page
                st.image(result['images'][0], caption="Page 1")
                
                # D√©tection
                annotations = labeler.label_image(result['saved_paths'][0])
                st.write(f"üîç {len(annotations['detections'])} d√©tections")
                
                # Afficher d√©tections
                for det in annotations['detections']:
                    st.write(f"- {det['class_name']}: {det['confidence']:.2%}")
```

### 8.2 Lancer Streamlit

```bash
streamlit run app_streamlit.py
```

---

## 9. D√©pannage

### 9.1 Erreurs Communes

**Erreur: "Module not found"**
```bash
pip install <nom_module>
```

**Erreur: "CUDA out of memory"**
```python
# R√©duire la taille du batch
config.YOLO_IMG_SIZE = 416  # Au lieu de 640
```

**Erreur: "PDF extraction failed"**
```bash
# Installer poppler (pour pdf2image)
# Windows: t√©l√©charger depuis https://github.com/oschwartz10612/poppler-windows
# Linux: sudo apt-get install poppler-utils
# Mac: brew install poppler
```

**Erreur: "Snowflake connection failed"**
```python
# Le notebook fonctionne en mode simulation sans Snowflake
# V√©rifier les variables d'environnement si n√©cessaire
```

### 9.2 V√©rifications

```python
# V√©rifier les imports
import torch
print(f"PyTorch: {torch.__version__}")
print(f"CUDA disponible: {torch.cuda.is_available()}")

# V√©rifier YOLO
from ultralytics import YOLO
model = YOLO("yolo11n.pt")
print("‚úÖ YOLO fonctionne")

# V√©rifier les chemins
from pathlib import Path
print(f"PDFs: {list(Path('data/pdfs').glob('*.pdf'))}")
print(f"Images: {list(Path('data/images').glob('*.png'))}")
```

---

## 10. Exemples d'Utilisation Rapide

### 10.1 Exemple Minimal

```python
# 1. Setup
# Ex√©cuter Section 1 du notebook

# 2. Traiter un PDF
pdf_path = "data/pdfs/mon_plan.pdf"
result = process_pdf(pdf_path)

# 3. D√©tecter
annotations = labeler.label_image(result['saved_paths'][0])

# 4. Visualiser
labeler.visualize_annotations(result['saved_paths'][0], annotations)
plt.show()
```

### 10.2 Exemple Complet

```python
# Voir le notebook complet pour l'exemple d√©taill√©
# Toutes les sections sont document√©es avec des exemples
```

---

## üìû Support

Pour toute question ou probl√®me:
1. V√©rifier la section D√©pannage
2. Consulter la documentation dans le notebook
3. V√©rifier les logs d'erreur

---

**Bon travail ! üöÄ**

